{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10578eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7eed913",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d2c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53730ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2654bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=False):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bca5ae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29000734",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "        \n",
    "        x3 = self.down2(x2)\n",
    "        \n",
    "        x4 = self.down3(x3)\n",
    "       \n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        x = self.up1(x5, x4)\n",
    "        \n",
    "        x = self.up2(x, x3)\n",
    "       \n",
    "        x = self.up3(x, x2)\n",
    "        \n",
    "        x = self.up4(x, x1)\n",
    "       \n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ef7c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unet = UNet(n_channels=3, n_classes=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61463e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel:\n",
    "    def __init__(self, start_schedule=0.0001, end_schedule=0.02, timesteps=5):\n",
    "        self.start_schedule = start_schedule\n",
    "        self.end_schedule = end_schedule \n",
    "        self.timesteps = timesteps \n",
    "        \n",
    "        \"\"\"\n",
    "        if \n",
    "           betas = [0.1, 0.2, 0.3, ....]\n",
    "        then\n",
    "           alphas = [0.9, 0.8, 0.7, ....]\n",
    "           alphas_cumprod = [0.9, 0.9*0.8, 0.9*0.8*0.7, ...]\n",
    "        \"\"\"\n",
    "        \n",
    "        self.betas = torch.linspace(start_schedule, end_schedule, timesteps)\n",
    "        self.alphas = 1 - self.betas \n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, axis=0)\n",
    "        \n",
    "    def forward(self,x_0, t, device):\n",
    "        \"\"\"\n",
    "        x_0: (B, C, H, W)\n",
    "        t: (B,)\n",
    "        \"\"\"\n",
    "        noise = torch.randn_like(x_0)\n",
    "        sqrt_alphas_cumprod_t = self.get_index_from_list(self.alphas_cumprod.sqrt(), t, x_0.shape)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self.get_index_from_list(torch.sqrt(1 - self.alphas_cumprod), t, x_0.shape)\n",
    "        \n",
    "        mean = sqrt_alphas_cumprod_t.to(device) * x_0.to(device)\n",
    "        variance = sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device)\n",
    "        \n",
    "        return mean + variance , noise.to(device)\n",
    "    \n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def get_index_from_list(values, t, x_shape):\n",
    "        batch_size = t.shape[0]\n",
    "        \"\"\"\n",
    "        pick the values from values \n",
    "        according to the indices stored in t\n",
    "        \"\"\"\n",
    "        result = values.gather(-1, t.cpu())\n",
    "        \"\"\"\n",
    "        if \n",
    "        x_shape = (5, 3, 64, 64)\n",
    "              -> len(x_shape) = 4 \n",
    "              -> len(x_shape) -1 = 3 \n",
    "        and thus we reshape 'out' to dims \n",
    "        [batch_size, 1, 1, 1,]\n",
    "        \"\"\"\n",
    "        \n",
    "        return result.reshape(batch_size,1,1,1).to(t.device)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "463c7d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaserScan:\n",
    "  \"\"\"Class that contains LaserScan with x,y,z,r\"\"\"\n",
    "  EXTENSIONS_SCAN = ['.bin']\n",
    "\n",
    "  def __init__(self, project=False, H=64, W=1024, fov_up=3.0, fov_down=-25.0):\n",
    "    self.project = project\n",
    "    self.proj_H = H\n",
    "    self.proj_W = W\n",
    "    self.proj_fov_up = fov_up\n",
    "    self.proj_fov_down = fov_down\n",
    "    self.reset()\n",
    "\n",
    "  def reset(self):\n",
    "    \"\"\" Reset scan members. \"\"\"\n",
    "    self.points = np.zeros((0, 3), dtype=np.float32)        # [m, 3]: x, y, z\n",
    "    self.remissions = np.zeros((0, 1), dtype=np.float32)    # [m ,1]: remission\n",
    "\n",
    "    # projected range image - [H,W] range (-1 is no data)\n",
    "    self.proj_range = np.full((self.proj_H, self.proj_W), -1,\n",
    "                              dtype=np.float32)\n",
    "\n",
    "    # unprojected range (list of depths for each point)\n",
    "    self.unproj_range = np.zeros((0, 1), dtype=np.float32)\n",
    "\n",
    "    # projected point cloud xyz - [H,W,3] xyz coord (-1 is no data)\n",
    "    self.proj_xyz = np.full((self.proj_H, self.proj_W, 3), -1,\n",
    "                            dtype=np.float32)\n",
    "\n",
    "    # projected remission - [H,W] intensity (-1 is no data)\n",
    "    self.proj_remission = np.full((self.proj_H, self.proj_W), -1,\n",
    "                                  dtype=np.float32)\n",
    "\n",
    "    # projected index (for each pixel, what I am in the pointcloud)\n",
    "    # [H,W] index (-1 is no data)\n",
    "    self.proj_idx = np.full((self.proj_H, self.proj_W), -1,\n",
    "                            dtype=np.int32)\n",
    "\n",
    "    # for each point, where it is in the range image\n",
    "    self.proj_x = np.zeros((0, 1), dtype=np.float32)        # [m, 1]: x\n",
    "    self.proj_y = np.zeros((0, 1), dtype=np.float32)        # [m, 1]: y\n",
    "\n",
    "    # mask containing for each pixel, if it contains a point or not\n",
    "    self.proj_mask = np.zeros((self.proj_H, self.proj_W),\n",
    "                              dtype=np.int32)       # [H,W] mask\n",
    "\n",
    "  def size(self):\n",
    "    \"\"\" Return the size of the point cloud. \"\"\"\n",
    "    return self.points.shape[0]\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.size()\n",
    "\n",
    "  def open_scan(self, filename):\n",
    "    \"\"\" Open raw scan and fill in attributes\n",
    "    \"\"\"\n",
    "    # reset just in case there was an open structure\n",
    "    self.reset()\n",
    "\n",
    "    # check filename is string\n",
    "    if not isinstance(filename, str):\n",
    "      raise TypeError(\"Filename should be string type, \"\n",
    "                      \"but was {type}\".format(type=str(type(filename))))\n",
    "\n",
    "    # check extension is a laserscan\n",
    "    if not any(filename.endswith(ext) for ext in self.EXTENSIONS_SCAN):\n",
    "      raise RuntimeError(\"Filename extension is not valid scan file.\")\n",
    "\n",
    "    # if all goes well, open pointcloud\n",
    "    scan = np.fromfile(filename, dtype=np.float32)\n",
    "    scan = scan.reshape((-1, 4)) # was -1,4 #########################################################################################\n",
    "\n",
    "    # put in attribute\n",
    "    points = scan[:, 0:3]    # get xyz\n",
    "    remissions = scan[:, 3]  # get remission\n",
    "    self.set_points(points, remissions)\n",
    "\n",
    "  def set_points(self, points, remissions=None):\n",
    "    \"\"\" Set scan attributes (instead of opening from file)\n",
    "    \"\"\"\n",
    "    # reset just in case there was an open structure\n",
    "    self.reset()\n",
    "\n",
    "    # check scan makes sense\n",
    "    if not isinstance(points, np.ndarray):\n",
    "      raise TypeError(\"Scan should be numpy array\")\n",
    "\n",
    "    # check remission makes sense\n",
    "    if remissions is not None and not isinstance(remissions, np.ndarray):\n",
    "      raise TypeError(\"Remissions should be numpy array\")\n",
    "\n",
    "    # put in attribute\n",
    "    self.points = points    # get xyz\n",
    "    if remissions is not None:\n",
    "      self.remissions = remissions  # get remission\n",
    "    else:\n",
    "      self.remissions = np.zeros((points.shape[0]), dtype=np.float32)\n",
    "\n",
    "    # if projection is wanted, then do it and fill in the structure\n",
    "    if self.project:\n",
    "      self.do_range_projection()\n",
    "\n",
    "  def do_range_projection(self):\n",
    "    \"\"\" Project a pointcloud into a spherical projection image.projection.\n",
    "        Function takes no arguments because it can be also called externally\n",
    "        if the value of the constructor was not set (in case you change your\n",
    "        mind about wanting the projection)\n",
    "    \"\"\"\n",
    "    # laser parameters\n",
    "    fov_up = self.proj_fov_up / 180.0 * np.pi      # field of view up in rad\n",
    "    fov_down = self.proj_fov_down / 180.0 * np.pi  # field of view down in rad\n",
    "    fov = abs(fov_down) + abs(fov_up)  # get field of view total in rad\n",
    "\n",
    "    # get depth of all points\n",
    "    depth = np.linalg.norm(self.points, 2, axis=1)\n",
    "\n",
    "    # get scan components\n",
    "    scan_x = self.points[:, 0]\n",
    "    scan_y = self.points[:, 1]\n",
    "    scan_z = self.points[:, 2]\n",
    "\n",
    "    # get angles of all points\n",
    "    yaw = -np.arctan2(scan_y, scan_x)\n",
    "    pitch = np.arcsin(scan_z / depth)\n",
    "\n",
    "    # get projections in image coords\n",
    "    proj_x = 0.5 * (yaw / np.pi + 1.0)          # in [0.0, 1.0]\n",
    "    proj_y = 1.0 - (pitch + abs(fov_down)) / fov        # in [0.0, 1.0]\n",
    "\n",
    "    # scale to image size using angular resolution\n",
    "    proj_x *= self.proj_W                              # in [0.0, W]\n",
    "    proj_y *= self.proj_H                              # in [0.0, H]\n",
    "\n",
    "    # round and clamp for use as index\n",
    "    proj_x = np.floor(proj_x)\n",
    "    proj_x = np.minimum(self.proj_W - 1, proj_x)\n",
    "    proj_x = np.maximum(0, proj_x).astype(np.int32)   # in [0,W-1]\n",
    "    self.proj_x = np.copy(proj_x)  # store a copy in orig order\n",
    "\n",
    "    proj_y = np.floor(proj_y)\n",
    "    proj_y = np.minimum(self.proj_H - 1, proj_y)\n",
    "    proj_y = np.maximum(0, proj_y).astype(np.int32)   # in [0,H-1]\n",
    "    self.proj_y = np.copy(proj_y)  # stope a copy in original order\n",
    "\n",
    "    # copy of depth in original order\n",
    "    self.unproj_range = np.copy(depth)\n",
    "\n",
    "    # order in decreasing depth\n",
    "    indices = np.arange(depth.shape[0])\n",
    "    order = np.argsort(depth)[::-1]\n",
    "    depth = depth[order]\n",
    "    indices = indices[order]\n",
    "    points = self.points[order]\n",
    "    remission = self.remissions[order]\n",
    "    proj_y = proj_y[order]\n",
    "    proj_x = proj_x[order]\n",
    "\n",
    "    # assing to images\n",
    "    self.proj_range[proj_y, proj_x] = depth\n",
    "    self.proj_xyz[proj_y, proj_x] = points\n",
    "    self.proj_remission[proj_y, proj_x] = remission\n",
    "    self.proj_idx[proj_y, proj_x] = indices\n",
    "    self.proj_mask = (self.proj_idx > 0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f7e7d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class  Data(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.scenes = sorted(os.listdir(self.path))\n",
    "        \n",
    "        self.files = [] \n",
    "        \n",
    "        for i in range(len(self.scenes)):\n",
    "            scene = os.path.join(self.path,  self.scenes[0])\n",
    "            pcd_files = sorted(os.listdir(scene))\n",
    "            for j in range(len(pcd_files)):\n",
    "                sample = {}\n",
    "                \n",
    "                pcd_file_path = os.path.join(scene, pcd_files[j])\n",
    "                \n",
    "                sample[\"pcd_path\"] = pcd_file_path \n",
    "                \n",
    "                self.files.append(sample)\n",
    "        \n",
    "    def __len__(self):\n",
    "            return len(self.files)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "            pcd_file_path = self.files[index][\"pcd_path\"]\n",
    "            \n",
    "            laser_object = LaserScan(project=True) \n",
    "            \n",
    "            laser_object.open_scan(pcd_file_path)\n",
    "            \n",
    "            return {\"pcd\":laser_object.proj_xyz}\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "796bc732",
   "metadata": {},
   "outputs": [],
   "source": [
    "path= \"/home/parvez_alam/Data/Kitti/Tracking/data_tracking_velodyne/training/velodyne\"\n",
    "train_ds = Data(path)\n",
    "train_loader = DataLoader(dataset=train_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "398f9c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_model = DiffusionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a86a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(Unet.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ae1a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Unet, train_loader, epochs):\n",
    "    for i in range(epochs):\n",
    "        running_loss = 0.0 \n",
    "        NUM_DISPLAY_IMAGES = 5\n",
    "        for n, data in enumerate(train_loader):\n",
    "            pcd = data[\"pcd\"].to(device).float().permute(0, 3, 1,2)\n",
    "            pcd = torch.cat((pcd, pcd, pcd, pcd, pcd), dim=0)\n",
    "            t = torch.linspace(0, diffusion_model.timesteps - 1, NUM_DISPLAY_IMAGES).to(torch.int64)\n",
    "            noisy_image, noise = diffusion_model.forward(pcd, t, device)\n",
    "            predicted_noise = Unet(noisy_image)\n",
    "            \n",
    "            loss = nn.functional.mse_loss(noise, predicted_noise)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss = running_loss + loss.item()\n",
    "            \n",
    "        \n",
    "        print(\"loss = {}  epoch = {}\".format(running_loss, i+1))\n",
    "        \n",
    "        checkpoint = {\n",
    "            \"epoch_number\": i+1,\n",
    "            \"model_state\" : Unet.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, \"trained_model.pth\")\n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbdb209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 3269.396974503994  epoch = 1\n",
      "loss = 3234.0628702640533  epoch = 2\n",
      "loss = 3218.611835360527  epoch = 3\n",
      "loss = 3130.535738825798  epoch = 4\n",
      "loss = 2809.7950353622437  epoch = 5\n",
      "loss = 2394.7433923482895  epoch = 6\n",
      "loss = 2075.1639620661736  epoch = 7\n",
      "loss = 1944.530089378357  epoch = 8\n",
      "loss = 1871.030537724495  epoch = 9\n",
      "loss = 1820.2345557808876  epoch = 10\n",
      "loss = 1782.9656631350517  epoch = 11\n",
      "loss = 1752.3656307458878  epoch = 12\n",
      "loss = 1725.881192266941  epoch = 13\n",
      "loss = 1701.8167003691196  epoch = 14\n",
      "loss = 1679.2851587235928  epoch = 15\n",
      "loss = 1658.6435523629189  epoch = 16\n",
      "loss = 1639.9128548204899  epoch = 17\n",
      "loss = 1622.9545706510544  epoch = 18\n",
      "loss = 1607.385467261076  epoch = 19\n",
      "loss = 1593.086888462305  epoch = 20\n",
      "loss = 1579.5763494968414  epoch = 21\n",
      "loss = 1566.8719760775566  epoch = 22\n",
      "loss = 1555.0524182021618  epoch = 23\n",
      "loss = 1543.509080350399  epoch = 24\n",
      "loss = 1532.616898238659  epoch = 25\n",
      "loss = 1522.1755167245865  epoch = 26\n",
      "loss = 1512.2073221206665  epoch = 27\n",
      "loss = 1502.3417765498161  epoch = 28\n",
      "loss = 1492.627289891243  epoch = 29\n",
      "loss = 1483.452546596527  epoch = 30\n",
      "loss = 1474.353783607483  epoch = 31\n",
      "loss = 1465.260570347309  epoch = 32\n"
     ]
    }
   ],
   "source": [
    "train(Unet, train_loader, 100)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "daa92ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/parvez_alam\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a26665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5514aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af787e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
